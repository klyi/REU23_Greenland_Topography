# -*- coding: utf-8 -*-
"""GPR_for1201_KY_230623.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10hp7_Hl3BfSE493gw1_9kvbTtWLcmLlz

# Gaussian Processing
"""
print("STARTING 1201 Full.")

#imports
print("Starting imports")
#basics
import time
print("Starting timer.")
startTime = time.time()

import numpy as np
import pandas as pd
import datetime
# import matplotlib.pyplot as plt #remove later

#cleaning
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

#metrics
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error

#Gaussian Process Specific
import sklearn.gaussian_process as gp
from sklearn.gaussian_process.kernels import RBF
from sklearn.gaussian_process import GaussianProcessRegressor

#h5 conversion
import h5py

print("Imports Complete")

datetimeCurr = datetime.datetime.now().strftime("%y%M%d_%H%M%S")
print(f"Current Datetime File Association: {datetimeCurr}")

"""## Get Data"""

#paths
data_full_ = '/home/kyi5/reu2023_team1/research/gpr/data/data_full.csv' #training and test combined
data_1201_ = '/home/kyi5/reu2023_team1/research/gpr/data/df_1201_validation_data.csv'

h5SavePath = '/home/kyi5/reu2023_team1/research/gpr/h5Files/'

#read data in
# df_train = pd.read_csv(df_train_)
# df_test_x = pd.read_csv(df_test_)
# df_test_y = pd.read_csv(df_pred_)

print("Reading Data In_")
df_all = pd.read_csv(data_full_)

df1201 = pd.read_csv(data_1201_)
print("Data read in completed.")

"""## Create functions from Homayra"""

print("Establishing RMSPE functions.")

def rmspe(y_true, y_pred):
    return np.sqrt(np.nanmean(np.square(((y_true - y_pred) / y_true))))*100

def rmspe_1(y_true, y_pred):
    return np.sqrt(np.nanmean(np.square(y_true - y_pred) / y_true))*100

print("Function established.")

"""## Clean Data/Prepare Data"""

print("Begin data cleaning.")

df1201 = df1201.drop(columns = ['Unnamed: 0'])
df_all = df_all.drop(columns = ['Unnamed: 0'])

#1201 drop location variables
df1201_feats = df1201.drop(columns = ['surf_x', 'surf_y'])

#df_all drop location variables
df_all_feats_target = df_all.drop(columns = ['surf_x', 'surf_y', 'track_bed_x', 'track_bed_y'])

#1201 order to align with df_all
df1201_feats_ordered = df1201_feats[['surf_vx', 'surf_vy', 'surf_elv', 'surf_dhdt', 'surf_SMB']]

#set the feature variables to our independent characteristic variables
feature_cols = ['surf_vx', 'surf_vy', 'surf_elv', 'surf_dhdt', 'surf_SMB']

#split into X and Y
X_given = df_all_feats_target[feature_cols]
Y_given = df_all_feats_target['track_bed_target']

#combine all known X and validation 1201 X for standardizing
X_all = np.concatenate((X_given, df1201_feats_ordered))

#make y into a dataframe to be standardized
Y_all = pd.DataFrame(Y_given)

print("Data cleaned.\nScaling beginning.")

#standardize
#Not setting feature range, let it be automatically determined
scaler_X = StandardScaler()
scaler_Y = StandardScaler()

X_all_std = scaler_X.fit_transform(X_all)
Y_all_std = scaler_Y.fit_transform(Y_all)

#can alternatively use the MinMaxScaler

print("Scaling Complete.\nSplitting Data Beginning.")

#split of 1201 data from X_all_std
X_non1201 = X_all_std[0:632706,:]
X_1201_data = X_all_std[632706:, :]

#generate a randomseed for training and testing split
generated = np.random.randint(0,1000,1)[0]
print(f"Generated random split for train-test: {generated}")

#set the train-test split
print("Running Subset Data set.")
train_size_ = .9

# subsection_x = X_non1201[0:50000]
# subsection_y = Y_all_std[0:50000]
# x_train, x_test, y_train, y_test = train_test_split(subsection_x, subsection_y, train_size = train_size_, test_size = 1-train_size_, random_state = generated)

#split training and test from df_all
x_train, x_test, y_train, y_test = train_test_split(X_non1201, Y_all_std, train_size = train_size_, test_size = 1-train_size_, random_state = generated)

print(f"Data train-split complete with: {train_size_ * 100}% training, {(1- train_size_) * 100}% testing")

"""## Modeling"""

print("Establishing model")
# Set the number of mini-batches
batch_size = 10000

# Set the number of optimization steps
num_epochs = 1

# Create the Gaussian Process regressor
model = GaussianProcessRegressor(kernel=RBF(length_scale=1.0))
print("Model established.")

print("Begin training model.")
# Mini-batch optimization loop
for epoch in range(num_epochs):
    # Shuffle the training data
    indices = np.random.permutation(x_train.shape[0])
    X_train_shuffled = x_train[indices]
    y_train_shuffled = y_train[indices]

    # Mini-batch training loop
    for i in range(0, x_train.shape[0], batch_size):
        X_batch = X_train_shuffled[i:i+batch_size]
        y_batch = y_train_shuffled[i:i+batch_size]

        # Fit the Gaussian Process on the mini-batch
        model.fit(X_batch, y_batch)
print("Model trained.")

print("Model Prediction Beginning")
params = model.kernel_.get_params()
y_pred_test, std = model.predict(x_test, return_std=True)

print("Model predicted.\nTransform data back to original scale.")

#get the original scale for the predicted Y
train_predict_full_scale = scaler_Y.inverse_transform(y_train.reshape(-1,1))
test_predict_full_scale = scaler_Y.inverse_transform(y_pred_test.reshape(-1,1))
y_test_given_full_range = scaler_Y.inverse_transform(y_test.reshape(-1,1))

# Evaluate the model performance
print("Print testing stats statements.")

#LOSSES
print('RMSE:',np.sqrt(mean_squared_error(y_test_given_full_range, test_predict_full_scale)))
print('RMSE Percentage:',rmspe(y_test_given_full_range, test_predict_full_scale))
print('RMSE Percentage-1:',rmspe_1(y_test_given_full_range, test_predict_full_scale))
print('Mean Absolute Error:', mean_absolute_error(y_test_given_full_range, test_predict_full_scale))
print('Mean Absolute Percentage Error:', mean_absolute_percentage_error(y_test_given_full_range, test_predict_full_scale))
print('R^2 Score:', r2_score(y_test_given_full_range, test_predict_full_scale))

print("End Train-Testing Time.")
endTrainingTestingTime = time.time()
print(f"Training-Testing Time: {endTrainingTestingTime-startTime:.03f}ms")

print("Predicting 1201")
start1201Prediction = time.time()
params = model.kernel_.get_params()

y_pred_1201, std = model.predict(X_1201_data, return_std=True)
pred1201_normScale = scaler_Y.inverse_transform(y_pred_1201)

end1201Prediction = time.time()
print(f"Predicting 1201 Complete.\nTime taken: {end1201Prediction-start1201Prediction:.03f}ms")

endTime = time.time()
print(f"Total Time Taken: {endTime - startTime:.03f}ms")
print("GPR COMPLETE")
print("**********************")

